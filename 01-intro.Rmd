# Introduction {#intro}

Imagine you’re a baby, eager to make sense of the bewildering world around you. From the sea of sounds surrounding you, you start picking out repeated pieces. Aha! your long-haired companion can be called a _doggie_. You rapidly add to your collection — that thing is a _banana_, someone can _eat_ it, people say _hi_ to one another. Before too long you’ve started putting these bits together — _hi doggie!_ — and changing them to suit your needs — _doggie eating bananas_. By the time you’re out of diapers, you’ve learned hundreds of words and can combine them in ever more complex ways.

Now imagine that you’re a scientist, eager to understand how this remarkable learning process unfolded. You might wonder, why was _doggie_ learned before _banana_ and before _eat_? How did these distinct words come to be joined by combinations and modifications such as _doggies_ and _bananas_ and _doggies ate bananas_? What happened when _doggie_ was overzealously said to have _eated_?

To get any traction on these questions, you’ll need to take into account that the child’s abilities and knowledge were ever-changing throughout this process. And while this particular sequence occurred for this one child, there is tremendous variation in individual children’s linguistic journeys. Moreover, these words and structures are in a specific language, and we need to understand how any of the many and varied languages of the world can be learned using the same underlying machinery.

In this thesis, I investigate lexical and morphological development, i.e. how young children learn words and word structures. I use dense datasets and computational models to find generalizations (1) across children, (2) over the course of development, and (3) among various languages. In the rest of this introductory chapter, I first briefly introduce the main data source used in my studies — the MacArthur-Bates Communicative Development Inventory [@fenson2007] as aggregated in Wordbank [@frank2017]. I then outline why these three dimensions of scale matter and what strengths and weaknesses various data sources have with respect to them. Finally, I give an overview of three completed studies, and a series of proposed future studies, of language learning at scale.

The MacArthur-Bates Communicative Development Inventory (CDI) is a checklist for parents to fill out to report on their child’s progress in learning language through the first three years of their life. In different versions of the form, parents mark whether their child “says” or “understands and says” particular words and word forms out of a list of several hundred. CDI forms have been adapted to dozens of languages. Because the CDI is standardized and inexpensive to administer, data from thousands of children has been collected by various research labs around the world.

To take advantage of the opportunity presented by the wide adoption of the CDI, my collaborators and I created Wordbank, an open repository that aggregates administrations of the CDI across languages. Wordbank contains around 83,000 administrations of CDIs in 30 languages, enabling a variety of novel analyses of language learning at scale. We believe this database is the largest and most diverse set of data on early language acquisition currently in existence.

For each of the three dimensions of scale listed above — across children, over development, and among languages — I describe below how the data from various sources can and can't contribute to these directions of generalization. Historically, the main empirical methods in the study of language learning have been diary studies, in-lab experiments, naturalistic observation (audio recordings in the lab or home), and parent report surveys such as  the CDI. Each method has been fruitful in building knowledge about children's language learning, though each has its strengths and weaknesses in terms of the richness of their data.

__Generalizing across children__.  Children vary enormously in rates of vocabulary development [@fenson1994; @frank2021] and in the routes they take during language learning [@nelson1973; @bates1991; @bates1994; @frank2021]. Given this large amount of individual variation, we need large sample sizes both to generalize across children and to study the degree to which learning processes are idiosyncratic vs. standardized. Diary studies are generally focused on just one child. In-lab studies study groups of children, but sample sizes are for the most part small, given the cost and time needed to conduct experiments. Small sample sizes result in many studies being under-powered, contributing to over-inflated, non-reproducible effects [@button2013; @osc2012]. Naturalistic recording datasets can have many subjects, but of course cost increases with sample size, especially because of the enormous labor intensiveness of transcription. Studies tend to lie on a trade-off between having a smaller number of subjects and a lot of data per subject -- at the extreme, the Speechome project with one subject and nearly constant audio recording [@roy2015] -- or a larger number of subjects with less data per subject (as is the case for most corpora in the CHILDES repository, which have between 1 and 42 subjects [@macwhinney2000]). Conversely, the CDI is relatively much cheaper to administer, so CDI datasets tend to have hundreds or thousands of subjects.

__Characterizing development__.  In-lab studies typically test either one group of children of a roughly similar age, or two or three groups of children, each of roughly similar age. The resulting claim is thus about children’s abilities at a broad age bin, e.g. “3 year olds can do X”, or a comparison of the abilities of children from several age bins, e.g. “3 year olds can’t do X but 4 year olds can, so X emerges between 3 and 4 years”. This is at best a very rough estimate of the age at which an ability may have developed in the average child, and not fine-grained enough to provide a detailed developmental trajectory, for individuals or in the aggregate. Diary studies and naturalistic recordings often measure children at much finer time points, collecting data anywhere from daily to every few weeks to every six months. However, typical sampling rates result in capturing only a tiny fraction of a child's total language output, making inferences about the onset or development of particular language phenomena very hard [@tomasello2004]. In the CDI, children are generally binned by month, so cross-sectional data gives information at one-month granularity, and longitudinal data gives information at a few-month granularity -- the length of the form means that it's not administered more often. In combination with large sample sizes, this allows for detailed developmental trajectories.

__Comparing and contrasting languages__.  Given the enormous diversity of the world's languages, for theories to generalize across languages, they need to be informed by data from many languages. Otherwise, we risk generating theories of language learning that only apply to a subset of languages and don’t enable us to understand language learning as a universal process. Since diary studies and naturalistic recordings are conducted on a per-child basis, the resulting data are in a single language (except in cases where the child is multilingual). In-lab studies also tend to be in a single language, although experiments using novel words or artificial grammars can in some ways sidestep the single-language specificity. For both kinds of data, comparing across studies in different languages, even if the phenomena under investigation are similar, is very challenging. Additionally, since studies tend to build on one another, subfields can become overly focused on specific phenomena. For example, much of the study of morphology learning focuses on how children learn the English past tense, which is a useful case study but is hardly prototypical across languages. However, the CDI has been adapted to many languages, and disparate datasets from around the world are now aggregated in the Wordbank repository [@frank2017]. Although there are challenges with the idiosyncrasies of different CDI forms and samples, this now allows for a wide range of fruitful cross-linguistic comparison [@braginsky2019; @frank2021].

In addition to the three data-related desiderata described above, it’s vital to consider how different data sources do and don’t allow us to distinguish among theories. The connection between empirical data and theoretical predictions is key to adjudicating between competing accounts of language learning. With CDI data, it can be challenging to form clear links to theory, since measurement is limited to the set of items on a standardized checklist. In-lab experiments, on the other hand, allow for carefully designed stimuli and measures that allow researchers to compare different hypotheses. In both cases, however, theories must be properly fleshed out to provide clear, testable predictions. For example, a long-time theoretical controversy has centered on the learning of the English past tense, with a dichotomy between “dual-route” (having separate representations for regular and irregular verbs) and “single-route” (having a unified representation for both) accounts. Throughout, researchers on both sides of the debate have made strong claims about the nature of mental representations, often without determining directly comparable, quantitative predictions of the various accounts. For example, evidence for commonality in how regular and irregular verbs are processed was taken as evidence against a dual-route system (and by extension against symbolic rules), but a system with graded, probabilistic application of rules could potentially be consistent with this data. Conversely, many claims about what single-route, neural network models could or could not in principle learn were subsequently disproven by a new model's success [@macwhinney1991; @plunkett1991; @plunkett1993; @westermann1995; @hoeffner1996; @nakisa1996; @plunkett1997; @plunkett1999; @hahn2000]. Such accounts need to be cached out into computational models to be fully specified enough for their assumptions and predictions to be compared on equal footing.

To summarize the discussion above, CDI datasets support cross-linguistic analyses with large samples and detailed developmental trajectories. However, their connection to theory is somewhat indirect and their temporal density can be limited. As such, the studies in this thesis first draw on the strengths of CDI data to investigate lexical development (Chapter \@ref(aoa-pred)), morphological development (Chapter \@ref(cdi-overreg)), and the relationship between them (Chapter \@ref(cdi-overreg)). I next turn to a computational modeling simulation paradigm to make detailed comparisons between models of morphological productivity (Chapter \@ref(prod-comp)). In the conclusion, I propose using a novel method of data collection to create a rich dataset on morphological development that can be used to quantitatively evaluate theories of morphology learning (Chapter \@ref(conclusion)).

First, in Chapter \@ref(aoa-pred) (published as @braginsky2019), we investigate lexical development by asking which properties of words make them easier or harder to learn. We use CDI data from thousands of children to estimate the learning trajectories of hundreds of words in ten languages, and predict these trajectories based on word-level properties of their meaning and linguistic environment. We examine the effects of these properties and the extent to which they are consistent or variable for several languages and lexical categories.

For the rest of the studies in this thesis, I focus on morphology learning. In Chapter \@ref(cdi-overreg) we ask how lexical development relates to morphological development. We use large CDI datasets in three languages to evaluate how children’s production of correct past tense forms of irregular verbs (ate) and overregularizations (eated) is driven by their vocabulary size, age, and combination of the two. We also use longitudinal data to examine individual children’s developmental trajectories of overregularization.

Chapter \@ref(prod-comp) also centers on morphology learning, but through a different lens. We use a computational simulation paradigm to investigate the similarities and differences among several leading models of morphological generalization. We perform this comparison using a space of language-agnostic, parametrically-varying corpora. Through a series of analyses, we show that these models make systematically differing predictions about morphological generalization, and we ascertain which assumptions of the models are critical to these differences.

Lastly, in Chapter \@ref(conclusion) I lay out a proposal for creating a rich dataset on the morphological development of a large sample of children and using these data to quantitatively evaluate theories of morphology learning. First, the planned cross-sectional study will assess which properties of words influence their propensity to be overregularized and irregularized. Next, a larger, longitudinal study will allow us to characterize the developmental trajectories of (over)generalization for individual children and words. Finally, instantiating theories of morphology into comparable computational models will allow us to test each theory quantitatively on equal footing, and meaningfully compare between proposals using the data from the two studies.

Taken together, these studies synthesize empirical and computational methods to investigate multiple domains of language development at scale. Focusing on lexical and morphological development, they clarify and enhance the empirical and theoretical landscape of language learning.
